{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seank1m/artificial-intelligence-for-robotics/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhYspwNmood9"
      },
      "source": [
        "# Past Sections from Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Assignment 2, we build upon the previous assignment and perform tasks related to regression problems.\n",
        "\n",
        "---\n",
        "\n",
        "First, we reload the dependencies from the previous assignment:"
      ],
      "metadata": {
        "id": "ymwBJpWQLjbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "XMCQQ7lFLRpV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cloud(data=None, x='x', y='y', z='z', color=None, *, max_points=10_000, **kwargs):\n",
        "\n",
        "    if max_points is not None and data is not None and len(data) > max_points:\n",
        "        import sys\n",
        "        print(f\"Warning: too many points, trying to show only {max_points:,} points.\", file=sys.stderr)\n",
        "        skip = len(data) // max_points\n",
        "        data = data[::skip]\n",
        "\n",
        "    if isinstance(data, np.ndarray):\n",
        "        m = data.shape[-1]\n",
        "        if m == 3:\n",
        "            x, y, z = data.T\n",
        "        elif m == 4:\n",
        "            x, y, z, color = data.T\n",
        "        data_frame = None\n",
        "    elif isinstance(data, pd.DataFrame):\n",
        "        data_frame = data\n",
        "    else:\n",
        "        data_frame = None\n",
        "\n",
        "    if (data_frame is not None\n",
        "        and isinstance(color, str)\n",
        "        and len(color) == 3\n",
        "        and color not in data_frame.columns\n",
        "        and all(c in data_frame.columns for c in color)\n",
        "    ):\n",
        "        update_color = data_frame[list(color)].to_numpy()\n",
        "        color = None\n",
        "    else:\n",
        "        update_color = None\n",
        "\n",
        "    fig = px.scatter_3d(\n",
        "        data_frame,\n",
        "        x=x, y=y, z=z,\n",
        "        color=color,\n",
        "        template=plot_cloud.template,\n",
        "        **kwargs,\n",
        "    )\n",
        "    if update_color is not None:\n",
        "        # has to be updated later because px.scatter_3d doesn't accept a matrix\n",
        "        fig.data[0].marker.color = update_color\n",
        "\n",
        "    return fig\n",
        "\n",
        "plot_cloud.template = dict(\n",
        "    layout=dict(\n",
        "        margin=dict(\n",
        "            # l=0, r=0,  # set left and right margin\n",
        "            b=0, t=0,  # set bottom and top margin\n",
        "        ),\n",
        "        scene=dict(\n",
        "            # xaxis_visible=False,  # hide axes\n",
        "            # yaxis_visible=False,\n",
        "            # zaxis_visible=False,\n",
        "            aspectmode='data',  # set aspect ratio\n",
        "        ),\n",
        "    ),\n",
        "    data=dict(\n",
        "        scatter3d=[\n",
        "            go.Scatter3d(\n",
        "                marker_size=1,  # set default marker size\n",
        "            ),\n",
        "        ],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "YuoBqAYJLYOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "n_clusters = 1000"
      ],
      "metadata": {
        "id": "J-SXcoPPLeM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now use the `request` package to download `df_test` that contains the data required for the rest of the assignment. `df_test` might be slightly different from the one you got in Assignment 1 depending on the features you used for the classification (it does not mean that the result you got in Assignment 1 is wrong)."
      ],
      "metadata": {
        "id": "jzj09VYSMFpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Shareable link\n",
        "shareable_link = 'https://drive.google.com/file/d/1-5gZVjT5nIt4oAvTTVLk1zAmg9z55Nb1/view?usp=sharing'\n",
        "\n",
        "# Extract file ID and create direct download URL\n",
        "file_id = shareable_link.split('/')[-2]\n",
        "url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "print(f\"Download URL: {url}\")\n",
        "\n",
        "# Download the file\n",
        "output = 'df_test.pkl'\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    with open(output, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"File downloaded as '{output}'\")\n",
        "else:\n",
        "    print(f\"Failed to download. Status code: {response.status_code}\")\n",
        "\n",
        "# Load the DataFrame (for pickle files)\n",
        "df_test = pd.read_pickle(output)\n",
        "\n",
        "# Show the first few rows\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "SiJEOwXRRGyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L68sytgP-8se"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "Assignment 2 will continue on from Assignment 1, using the clustered and classified point cloud. We will use linear and non-linear regression models to resample the point cloud (the marking criteria is provided in brackets):\n",
        "\n",
        "1. Apply linear regression to buildings (30%)\n",
        "2. Answer the questions related to the linear regression (20%)\n",
        "3. Apply the GP for ground estimation (30%)\n",
        "4. Answer the questions related to the GP section (20%)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "You are required to:\n",
        " - Model each cluster classified as *building* with a *linear regression* model.\n",
        " - Model every point classified as *terrain* with a *Gaussian process* model.\n",
        "\n",
        " > Begin by inserting Assignment 1 here. Note: by shift-clicking and then right-clicking, you can select multiple notebook cells, copy, and paste them across notebooks.\n",
        "\n",
        " > In the subsequent tasks, use the test data set `df_test` and group the points into **100 clusters**. Do not use the ground truth class `labels`, only the predicted values `pred`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3IxJZBiCzoe"
      },
      "source": [
        "# 1. Linear Regression\n",
        "\n",
        "As we are working in 3 dimensions, we are going to use 2 dimensions to estimate the 3rd. As such, There are 3 possible choices for the estimated variable: $x$, $y$, or $z$. Luckily, it is easy to know which model to select: the one with the lowest *mean squared error*.\n",
        "\n",
        "> Define a function to perform linear regression in each of the 3 dimensions, and select the model with the best error.\n",
        "\n",
        "> Apply this process to each cluster, replacing the points with a linear approximation.\n",
        "\n",
        "> The model can be used at arbitrary locations, use `bounding_grid` to query each model on a regular grid instead of at the original (training) locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmAO-o6Y-_LW"
      },
      "outputs": [],
      "source": [
        "# df_walls = df_test[df_test['pred'] == 'buildings']\n",
        "positions = df_walls[['x','y','z']].to_numpy()\n",
        "assignment = df_walls['cluster'].to_numpy()\n",
        "print(positions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQLSHWC8bQVQ"
      },
      "outputs": [],
      "source": [
        "def bounding_grid(x, n=None):\n",
        "    \"\"\"\n",
        "    Replaces a set of points by a similar number of points on a regular grid\n",
        "    spanning the bounds of the original point set.\n",
        "\n",
        "    x: numpy array, shape [n, d], n points in d dimensions.\n",
        "    n: int (optional), minimum number of points to generate.\n",
        "    \"\"\"\n",
        "    d = x.shape[-1]\n",
        "    if n is None:\n",
        "        n = len(x)\n",
        "    mins = x.min(axis=0)\n",
        "    maxs = x.max(axis=0)\n",
        "    rngs = (maxs - mins)\n",
        "    nums = np.ceil(rngs * np.power(n/rngs.prod(), 1/d)).astype(int)\n",
        "    axes = [np.linspace(mn, mx, ns) for mn, mx, ns in zip(mins, maxs, nums)]\n",
        "    grid = np.stack(np.meshgrid(*axes, indexing='ij'), axis=-1)\n",
        "    return grid.reshape(nums.prod(), d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upelZbFYGQMo"
      },
      "outputs": [],
      "source": [
        "## TODO START\n",
        "\n",
        "def lin_reg(points):\n",
        " ..............##TODO................\n",
        "\n",
        "    return points\n",
        "\n",
        "\n",
        "positions_lin = []\n",
        "for i in range(n_clusters):\n",
        "  ##TODO\n",
        "     ...\n",
        "    points_lin = lin_reg(points)\n",
        "    positions_lin.append(points_lin)\n",
        "positions_lin = np.concatenate(positions_lin)\n",
        "\n",
        "plot_cloud(positions).show()\n",
        "plot_cloud(positions_lin).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Linear regression Questions (In less than 100 words each):\n",
        "- How shall we estimate the performance of the linear regression?\n",
        "- What could we do if the the fitting of the plane was not good enough?\n",
        "- How can we tell if the model is overfitting or underfitting our data?"
      ],
      "metadata": {
        "id": "_-3IDmF_P7pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dC7PArgEQFhn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhf0mhEnY2oQ"
      },
      "source": [
        "# 3. Gaussian Process Regression\n",
        "\n",
        "Similarly, Gaussian process models can be used in higher dimensions too. Model the ground with a GP, where the height is the estimated quantity.\n",
        "\n",
        "> Perform Gaussian process regression on the height data.\n",
        "\n",
        "> Note: we are no longer working with zero-mean data, and the kernel hyperparameters should be  chosen carefully.\n",
        "\n",
        "> With the 2-dimensional input, the kernel function needs to change: it should take 2D vectors and return scalars.\n",
        "\n",
        "> The training data should be considered noisy, with a standard deviation of 1cm (point cloud units are in meters).\n",
        "\n",
        "> The model can be used at arbitrary locations, use `bounding_grid` to query the model on a regular grid instead of at the original (training) locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Diz5cXPbZAo0"
      },
      "outputs": [],
      "source": [
        "df_ground = df_test[df_test['pred'] == 'terrain']\n",
        "locations = df_ground[['x','y']].to_numpy()\n",
        "heights = df_ground['z'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFmaGmd2ZgeD"
      },
      "outputs": [],
      "source": [
        "# See the mean and variance of the modelled property\n",
        "mu = ... # TODO\n",
        "sigma=...  # TODO\n",
        "mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKxFPdfoZR4l"
      },
      "outputs": [],
      "source": [
        "from numpy import exp, sqrt, sum\n",
        "from numpy import diag, eye\n",
        "from numpy.linalg import inv, solve\n",
        "\n",
        "lengthscale =  # meter  # TODO\n",
        "\n",
        "def kernel(x1, x2, sigma=sigma, lengthscale=lengthscale):\n",
        "    return  ... # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1_51OU5aOAv"
      },
      "outputs": [],
      "source": [
        "## inputs\n",
        "xd = ...\n",
        "yd = ...\n",
        "nd = ...\n",
        "xq = ...\n",
        "\n",
        "std_n =#TODO\n",
        "Snn = #TODO\n",
        "\n",
        "## evaluating the kernel\n",
        "#TODO\n",
        "Kdd = ...\n",
        "Kqd = ...\n",
        "Kdq = ...\n",
        "Kqq = ...\n",
        "\n",
        "## the GP equations\n",
        "#TODO\n",
        "\n",
        "mean_q = #TODO\n",
        "cov_qq =#TODO\n",
        "var_q  =   # TODO\n",
        "std_q  =  #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the estimated height of the ground alongside with the uncertainty:"
      ],
      "metadata": {
        "id": "e5u89xboNmNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# plot the ground truth\n",
        "\n",
        "# then plot the estimation with the uncertainty\n"
      ],
      "metadata": {
        "id": "XQn8Yz9SNnfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. GP Questions (In less than 100 words each):\n",
        "- What is happening in the area where no points are rpovided to the GP (discuss the mean values and the uncertainty)?\n",
        "- Which kernel we are using and why this is important?\n",
        "\n"
      ],
      "metadata": {
        "id": "dnEEynL6OE3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zdjYvmRxQwPB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}